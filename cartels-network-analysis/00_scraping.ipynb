{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1917ec6-6028-4e75-a424-bdcad4b62eb7",
   "metadata": {},
   "source": [
    "# Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97f34308-4060-4757-978c-2c848dc5af81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import requests\n",
    "import time\n",
    "import bs4 as bs\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import locale\n",
    "from spacy import displacy\n",
    "from datetime import datetime\n",
    "from pprint import pprint\n",
    "from collections import defaultdict\n",
    "import iso3166\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc2776a5-0436-413c-9c9d-5ef8ea05b6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python3 -m pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.0.0/en_core_web_sm-3.0.0.tar.gz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5f2b23b-7eb8-478e-8efa-08f6eb84828f",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "remove = [\"'\", \"‘\", \"’\"]\n",
    "images_path = \"./images/\"\n",
    "data_path = \"./data/\"\n",
    "organizations_tags = set()\n",
    "individuals_tags = set()\n",
    "countries = [country.lower() for country in iso3166.countries_by_name.keys()]\n",
    "countries_set = set()\n",
    "organizations_set = set()\n",
    "individuals_set = set()\n",
    "individual_titles = [\"History\", \"Criminal Activities\", \"Geography\", \"Allies and Enemies\", \"Prospects\"]\n",
    "organization_titles = [\"History\", \"Leadership\", \"Criminal Activity\", \"Geography\", \"Allies and Enemies\", \"Prospects\"]\n",
    "individuals_url = \"https://insightcrime.org/criminal-actors/?filter=personalities&country=0&orderby=\"\n",
    "organizations_url = \"https://insightcrime.org/criminal-actors/?filter=armed_groups&country=0&orderby=\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7801724-a0c1-4873-b5ed-e8f504789c6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "headers = {\n",
    "    'Access-Control-Allow-Origin': '*',\n",
    "    'Access-Control-Allow-Methods': 'GET',\n",
    "    'Access-Control-Allow-Headers': 'Content-Type',\n",
    "    'Access-Control-Max-Age': '3600',\n",
    "    'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:52.0) Gecko/20100101 Firefox/52.0'\n",
    "    }\n",
    "\n",
    "url = \"https://insightcrime.org/caribbean-organized-crime-news/400-mawozo/\"\n",
    "req = requests.get(url, headers)\n",
    "soup = bs.BeautifulSoup(req.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2ee71df-1b70-47cd-8e04-571265f59bb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "677bd2e5-4e32-41a0-9b76-e6e8319a14bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get url content (soup)\n",
    "def get_soup(url):\n",
    "    req = requests.get(url, headers)\n",
    "    soup = bs.BeautifulSoup(req.content, 'html.parser')\n",
    "    \n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13db3a4e-e147-468e-ac3a-18148f5350c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_name_and_alias(soup, entity_set):\n",
    "    target = soup.find(\"h1\").text\n",
    "\n",
    "    # Get name and alias\n",
    "    if \"alias\" in target:\n",
    "        name = target.split(\", alias\")[0].strip()\n",
    "        alias = target.split(\", alias\")[1].strip()\n",
    "        alias = ''.join(c for c in alias if not c in remove)\n",
    "    else:\n",
    "        name = target\n",
    "        alias = None\n",
    "    entity_set.add(name)\n",
    "    return name, alias\n",
    "\n",
    "def get_image(soup, name, folder):\n",
    "    images = soup.find_all('img', alt=True)\n",
    "    for image in images:\n",
    "        if name in image[\"alt\"]:\n",
    "            image_url = image[\"src\"]\n",
    "            image_data = requests.get(image_url).content\n",
    "            image_destination = f\"{images_path}{folder}/{name.replace(' ', '-').replace('/', '-')}.jpg\".lower()\n",
    "            with open(image_destination, \"wb\") as file: \n",
    "                file.write(image_data)\n",
    "    return image_destination\n",
    "\n",
    "def get_tags_and_country(soup, countries, entity_tags):\n",
    "    tags_list = soup.find(\"div\", {\"class\":\"list-tags\"}).find_all(\"li\")\n",
    "    tags = [tag.text.lower() for tag in tags_list]\n",
    "    country = None\n",
    "    for tag in tags:\n",
    "        entity_tags.add(tag)\n",
    "        if any(tag in country for country in countries):\n",
    "            country = tag\n",
    "        elif any(country.split(\",\")[0] in tag for country in countries):\n",
    "            country = tag.split(\" \")[0]\n",
    "        countries_set.add(country)\n",
    "    return tags, country\n",
    "\n",
    "def get_details(soup, entity_set, titles):\n",
    "    output = {}\n",
    "    details = soup.find(\"div\", {\"class\":\"single-content\"})\n",
    "    title = \"Summary\"\n",
    "    i = 0\n",
    "    detail = \"\"\n",
    "    for item in details:\n",
    "        # Deal with Ex-FARC Mafia page specificities\n",
    "        if (item.name == \"h2\") or (item.name == \"h3\") or ((get_name_and_alias(soup, entity_set) == \"Ex-FARC Mafia\") and (item.text == \"Leadership\")):\n",
    "            # Stop at next header\n",
    "            output[title] = detail#.replace(\"\\n\", \" \") \\\n",
    "                                  #.replace(\"\\xa0\", \" \") \\\n",
    "                                  #.replace(\"\\\\\", \"\") \\\n",
    "            \n",
    "            title = titles[i]\n",
    "            i += 1\n",
    "            detail = \"\"\n",
    "        if (item.name == \"p\") and (item.get(\"style\") == None):# or (\"SEE ALSO\" not in item.contents)):\n",
    "            detail += item.text\n",
    "        output[title] = detail#.replace(\"\\n\", \" \") \\\n",
    "                              #.replace(\"\\xa0\", \" \") \\\n",
    "                              #.replace(\"\\\\\", \"\") \\\n",
    "                              #.strip()\n",
    "\n",
    "    return output\n",
    "    \n",
    "def ensure_page_is_profile(soup, url):\n",
    "    target = soup.find(\"div\", {\"class\": \"text\"})\n",
    "    if target != None:\n",
    "        url = target.find(\"a\", href=True)[\"href\"]\n",
    "        soup = get_soup(url)\n",
    "        return soup, url\n",
    "    else:\n",
    "        return soup, url\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54ca1752-1629-42a9-90c1-658ce2e2e35f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_latest_update_in_english(soup):\n",
    "    locale.setlocale(locale.LC_TIME, 'en_US.UTF-8')\n",
    "    latest_update = soup.find(\"span\", {\"class\":\"autor\"}).text.strip().replace(\"LATEST UPDATE \", \"\") \\\n",
    "                                                                     .replace(\" BY INSIGHT CRIME\", \"\") \\\n",
    "                                                                     .replace(\"\\n\", \"\")\n",
    "    try:\n",
    "        latest_update = datetime.strptime(latest_update, \"%B %d, %Y\").date()\n",
    "    except ValueError:\n",
    "        try:\n",
    "            latest_update = datetime.strptime(latest_update, \"%d %b %Y\").date()\n",
    "        except ValueError:\n",
    "            try:\n",
    "                latest_update = datetime.strptime(latest_update, \"%Y-%m-%d\").date()\n",
    "            except:\n",
    "                try:\n",
    "                    latest_update = datetime.strptime(latest_update, \"%d %B, %Y\").date()\n",
    "                except:\n",
    "                    latest_update = datetime.strptime(latest_update, \"%b %d, %Y\").date()\n",
    "    return latest_update\n",
    "            \n",
    "def get_latest_update_in_spanish(soup):\n",
    "    locale.setlocale(locale.LC_TIME, 'es_US.UTF-8')\n",
    "    latest_update = soup.find(\"span\", {\"class\":\"autor\"}).text.strip().replace(\"LATEST UPDATE \", \"\") \\\n",
    "                                                                     .replace(\" BY INSIGHT CRIME\", \"\") \\\n",
    "                                                                     .replace(\"\\n\", \"\")\n",
    "    try:\n",
    "        latest_update = datetime.strptime(latest_update, \"%B %d, %Y\").date()\n",
    "    except ValueError:\n",
    "        try:\n",
    "            latest_update = datetime.strptime(latest_update, \"%d %b %Y\").date()\n",
    "        except ValueError:\n",
    "            try:\n",
    "                latest_update = datetime.strptime(latest_update, \"%Y-%m-%d\").date()\n",
    "            except:\n",
    "                try:\n",
    "                    latest_update = datetime.strptime(latest_update, \"%d %B DE %Y\").date()\n",
    "                except:\n",
    "                    try:\n",
    "                        latest_update = datetime.strptime(latest_update, \"%Y-%m-%d %H:%M:%S\").date()\n",
    "                    except:\n",
    "                        latest_update = datetime.strptime(latest_update, \"%d %B, %Y\").date()\n",
    "    locale.setlocale(locale.LC_TIME, \"en_US.UTF-8\")\n",
    "    return latest_update\n",
    "            \n",
    "def get_latest_update(soup):\n",
    "    try:\n",
    "        latest_update = get_latest_update_in_english(soup)\n",
    "    except:\n",
    "        latest_update = get_latest_update_in_spanish(soup)\n",
    "    return latest_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8bc88cca-ed28-4f69-9edc-2da1573ca113",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get profile\n",
    "def get_profile(url, entity_set, entity_tags, titles, folder):\n",
    "    # Get target\n",
    "    temp_soup = get_soup(url)\n",
    "    soup, url = ensure_page_is_profile(temp_soup, url)\n",
    "    \n",
    "    profile = {}\n",
    "    profile[\"url_profile\"] = url\n",
    "   \n",
    "    # Get name and alias\n",
    "    profile[\"name\"], profile[\"alias\"] = get_name_and_alias(soup, entity_set)\n",
    "\n",
    "    # Get image\n",
    "    profile[\"image\"] = get_image(soup, profile[\"name\"], folder)\n",
    "    \n",
    "    # Get latest update date\n",
    "    profile[\"latest_update\"] = get_latest_update(soup)\n",
    "        \n",
    "    # Get tags\n",
    "    profile[\"tags\"], profile[\"country\"] = get_tags_and_country(soup, countries, entity_tags)\n",
    "\n",
    "    # Get details\n",
    "    try:\n",
    "        for k, v in get_details(soup, entity_set, titles).items():\n",
    "            profile[k] = v\n",
    "    except IndexError:\n",
    "        # Dealing with exceptional case of organization found in individual profiles\n",
    "        # (not a problem, as organization will be caught elsewhere and leader as well)\n",
    "        return profile\n",
    "\n",
    "    # Tracking\n",
    "    #print(profile)\n",
    "    return profile\n",
    "\n",
    "#get_organization(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed7ff5a6-b51f-497d-a417-f9c62d5da257",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time:5.86\n"
     ]
    }
   ],
   "source": [
    "def scrape_data(url, func, entity_set, entity_tags, titles, folder):\n",
    "    output = {}\n",
    "    soup = get_soup(url)\n",
    "    pages = [page.text.strip() for page in soup.find_all(\"li\", {\"class\":\"page-item\"}) if page.text.strip() != \"\"]\n",
    "    for page in pages:\n",
    "        if page == \"1\":\n",
    "            pass\n",
    "        else:\n",
    "            next_url = f\"{url.split('?')[0]}page/{page}/?{url.split('?')[1]}\"\n",
    "            soup = get_soup(next_url)\n",
    "        \n",
    "        boxes = [box for box in soup.find_all(\"div\", {\"class\":\"row row-main\"})[0].children if box != \"\\n\"]\n",
    "        for box in boxes:\n",
    "            image_box = box.find(\"div\", {\"class\":\"image-box\"})\n",
    "            target_url = image_box.find(\"a\", href=True)[\"href\"]\n",
    "            target_name = box.find(\"h2\").text\n",
    "            output[target_name] = func(target_url, entity_set, entity_tags, titles, folder)\n",
    "\n",
    "    return output\n",
    "\n",
    "organizations = scrape_data(organizations_url, get_profile, organizations_set, organizations_tags, organization_titles, \"organizations\")\n",
    "individuals = scrape_data(individuals_url, get_profile, individuals_set, individuals_tags, individual_titles, \"individuals\")\n",
    "end_time = time.time()\n",
    "execution_time = round((end_time - start_time) / 60, 2)\n",
    "print(f\"Execution time:{execution_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e1b23f0-a6d2-41ed-8afb-e415ba131d70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "del individuals[\"Rastrojos\"]\n",
    "organizations_df = pd.DataFrame.from_dict(organizations, orient=\"index\")\n",
    "individuals_df = pd.DataFrame.from_dict(individuals,orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b0310da-a5a4-43d0-b84f-b1f44a1a1da4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "organizations_df.to_csv(f\"{data_path}organizations.csv\")\n",
    "individuals_df.to_csv(f\"{data_path}individuals.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203da47b-6850-4c1e-a3fd-30775deca046",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Next\n",
    "- Add a More context key with all links in text\n",
    "- Turn into a function\n",
    "- Do the same for organization\n",
    "- Add sentiment analysis for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2795c339-a251-4d9f-8366-4f8953942943",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{data_path}organizations.txt\", \"w\") as f:\n",
    "    for organization in list(organizations_set):\n",
    "        f.write(organization + \"\\n\")\n",
    "        \n",
    "with open(f\"{data_path}organizations_tags.txt\", \"w\") as f:\n",
    "    for organization_tag in list(organizations_tags):\n",
    "        f.write(organization_tag + \"\\n\")\n",
    "        \n",
    "with open(f\"{data_path}individuals_tags.txt\", \"w\") as f:\n",
    "    for individual_tag in list(individuals_tags):\n",
    "        f.write(individual_tag + \"\\n\")\n",
    "        \n",
    "with open(f\"{data_path}countries.txt\", \"w\") as f:\n",
    "    for country in list(countries_set):\n",
    "        f.write(organization + \"\\n\")\n",
    "        \n",
    "with open(f\"{data_path}individuals.txt\", \"w\") as f:\n",
    "    for individual in individuals_df[\"name\"].values:\n",
    "        f.write(individual + \"\\n\")\n",
    "        \n",
    "with open(f\"{data_path}aliases.txt\", \"w\") as f:\n",
    "    for alias in individuals_df[\"alias\"].values:\n",
    "        if alias != None:\n",
    "            f.write(alias + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56f7ae5-2119-41d8-8803-2959240dd3da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
