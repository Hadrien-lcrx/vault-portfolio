{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd70ab17-2a8f-4673-b66c-0998929a3dae",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "404ea066-2843-49c5-847a-2df319809c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d5b64c0-0943-470e-9d68-a5f51644b00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(predictions, true_labels):\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    precision = precision_score(true_labels, predictions, average=\"weighted\")\n",
    "    recall = recall_score(true_labels, predictions, average=\"weighted\")\n",
    "    f1 = f1_score(true_labels, predictions, average=\"weighted\")\n",
    "    confusion = confusion_matrix(true_labels, predictions)\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"confusion_matrix\": confusion\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a20f8eb-ea9f-49cf-981b-4ca322fd6df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset in 12.07s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "df = pd.read_csv(\"./data/accidents_engineered_ordinal.csv\")\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "#Subtract Start Time from The End Time\n",
    "total_time = end - start\n",
    "print(f\"Loaded dataset in {round(total_time, 2)}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70910056-df43-4af4-8044-b8aef93878f6",
   "metadata": {},
   "source": [
    "### Standardization (StandardScaler())\n",
    "- `nbv`\n",
    "- `lartpc`\n",
    "- `larrout`\n",
    "- `vma`\n",
    "- `occutc`?\n",
    "- `age`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ee91bdd-2696-4147-aea9-01bab9789c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_standardize = [\"nbv\", \"age\"]\n",
    "\n",
    "# Instantiate the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the columns you want to standardize\n",
    "scaler.fit(df[columns_to_standardize])\n",
    "\n",
    "# Transform the selected columns to their standardized values\n",
    "df[columns_to_standardize] = scaler.transform(df[columns_to_standardize])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b0a109-7849-4c35-97c2-87cf400c719a",
   "metadata": {},
   "source": [
    "## Scaling (MinMaxScaler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ca9ee01-2ff2-4188-9480-1ac7c9791887",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_scale = [\"nbv\", \"age\"]\n",
    "\n",
    "# Instantiate the MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the scaler on the columns you want to scale\n",
    "scaler.fit(df[columns_to_scale])\n",
    "\n",
    "# Transform the selected columns to their scaled values\n",
    "df[columns_to_scale] = scaler.transform(df[columns_to_scale])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b046a388-14b5-4714-b547-84721a44e90a",
   "metadata": {},
   "source": [
    "## Drop rows with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33753f9a-f7d2-42b8-a085-7ad0ab8a0802",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5194b9ea-4b3d-47e3-bc28-74bf925df28d",
   "metadata": {},
   "source": [
    "## Encode final variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d131404e-54c1-4e06-bf0b-0705431395d0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mapping = \"ordinal\"\n",
    "if mapping == \"ordinal\":\n",
    "    grav_order = [1, 2, 3, 4]\n",
    "    df[\"grav\"] = pd.Categorical(df[\"grav\"], categories=grav_order, ordered=True)\n",
    "if mapping == \"binary\":\n",
    "    df[\"grav\"] = pd.Categorical(df[\"grav\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc35eec5-693a-4c9c-93a4-069112e9ad9c",
   "metadata": {},
   "source": [
    "## Convert columns to categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec3e70f0-ef9d-480c-9976-70c29286cef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = [\"col\", \"prof\", \"plan\", \"situ\", \"obs\", \"choc\", \"manv\",\n",
    "               \"lum\", \"agg\", \"catr\", \"circ\", \"catv\", \"catu\", \"sexe\"]\n",
    "\n",
    "for col in cat_columns:\n",
    "    df[col] = df[col].astype(\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d968479-5c89-46cd-8b4b-d6f79d152fae",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66776c92-fa74-4843-8f8d-88e2758ab068",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote engineered dataset in 105.31s\n",
      "There are 2,355,812 rows and 23 columns in the final dataset that will be used for modeling.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "df.to_csv(\"./data/accidents_preprocessed.csv\", index=False)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "total_time = end - start\n",
    "print(f\"Wrote engineered dataset in {round(total_time, 2)}s\")\n",
    "print(f\"There are {len(df):,} rows and {len(df.columns)} columns in the final dataset that will be used for modeling.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e6a45a0-1fef-4454-930f-5bd321395cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2355812 entries, 0 to 2355811\n",
      "Data columns (total 23 columns):\n",
      " #   Column         Dtype   \n",
      "---  ------         -----   \n",
      " 0   col            category\n",
      " 1   lum            category\n",
      " 2   agg            category\n",
      " 3   catr           category\n",
      " 4   circ           category\n",
      " 5   nbv            float64 \n",
      " 6   prof           category\n",
      " 7   plan           category\n",
      " 8   situ           category\n",
      " 9   catv           category\n",
      " 10  obs            category\n",
      " 11  choc           category\n",
      " 12  manv           category\n",
      " 13  catu           category\n",
      " 14  sexe           category\n",
      " 15  grav           category\n",
      " 16  age            float64 \n",
      " 17  month_sin      float64 \n",
      " 18  month_cos      float64 \n",
      " 19  DayOfWeek_sin  float64 \n",
      " 20  DayOfWeek_cos  float64 \n",
      " 21  TimeOfDay_sin  float64 \n",
      " 22  TimeOfDay_cos  float64 \n",
      "dtypes: category(15), float64(8)\n",
      "memory usage: 177.5 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "565f373b-1293-4d4e-9062-27b0bf1c1bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last run at 18:39:06\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(f\"Last run at {current_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5e697b-f9fe-48fa-8738-0482aac518b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
